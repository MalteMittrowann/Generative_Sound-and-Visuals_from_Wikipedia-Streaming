# **SONIC WIKIPEDIA**

### **Generative Audiovisuelle Echtzeit-Installation**

[**LIVE INSTALLATION STARTEN**](https://maltemittrowann.com/wiki-sonic/)

*Der globalen Puls des menschlichen Wissens in Echtzeit.*

## **Projekt√ºbersicht**

**"Sonic Wikipedia"** ist eine cross-mediale generative Kunstinstallation, die die unsichtbare digitale Infrastruktur der weltweiten Wissensproduktion sinnlich erfahrbar macht.

Das System verbindet sich in Echtzeit mit dem globalen Datenstrom der Wikimedia Foundation. Jede Bearbeitung (*Edit*), die irgendwo auf der Welt auf Wikipedia get√§tigt wird, wird augenblicklich in **Licht** und **Klang** √ºbersetzt.

Wikipedia wird oft als statische Enzyklop√§die wahrgenommen. Im Hintergrund jedoch agiert ein komplexes, lebendiges √ñkosystem aus menschlichen Autoren und automatisierten Bots. Dieses Projekt visualisiert und sonifiziert diesen **"Herzschlag des Internets"**.

## **Konzept & Forschungsfrage**

Das Projekt behandelt die Wikipedia-API nicht als reine Datenquelle, sondern als generativen "Keim" (*Seed*). Ein zentraler Forschungsaspekt liegt in der √§sthetischen Unterscheidung zwischen **menschlicher** und **maschineller** Aktivit√§t.

| Forschungsaspekt | Beschreibung |
| :---- | :---- |
| **Cross-Mediale √úbersetzung** | Wie lassen sich abstrakte Metadaten (Byte-Gr√∂√üe, Nutzer-Typ, Artikell√§nge, Sprache) in sensorische Parameter (Frequenz, Klangfarbe, Position im 3D-Raum) √ºbersetzen? |
| **Mensch vs. Maschine** | Das System weist Akteuren unterschiedliche Signaturen zu. **Bots** klingen kalt und pr√§zise (Rechteckwellen), **Menschen** warm und organisch (S√§gezahnwellen). |
| **Globalit√§t** | Durch die Verortung der Edits (im Stereobild und auf einem virtuellen Globus) wird die weltweite Gleichzeitigkeit der Wissensproduktion visualisiert. |

## **Systemarchitektur (Dual Implementation)**

Das Projekt wurde in zwei technischen Iterationen entwickelt, um unterschiedliche √ñkosysteme zu erforschen:

### **Der Forschungs-Prototyp (Offline / Lokal)**

*High-Performance Umgebung f√ºr Audio-Synthese und Netzwerk-Kommunikation.*

* **Backend:** Python 3.13 (Daten-Stream & Parsing)  
* **Kommunikation:** OSC (Open Sound Control) via UDP  
* **Audio-Engine:** SuperCollider (Hochleistungs-Echtzeitsynthese)  
* **Visuals:** Python (Pygame mit Custom 3D-Projektions-Engine)

### **Die √ñffentliche Installation (Online / Web)**

*Barrierefreie Portierung auf moderne Web-Standards.*

* **Core:** JavaScript (ES6+), Server-Sent Events (SSE)  
* **Visuals:** Three.js (WebGL) f√ºr hardwarebeschleunigtes 3D-Rendering & Bloom  
* **Audio:** Web Audio API (Nachbau der SuperCollider-Synthese im Browser)

## **Features & Mappings**

### **Visuelle Parameter**

* **X-Achse:** Repr√§sentiert die Sprache/das Wiki (z.B. Englisch links, Deutsch rechts, Japanisch Mitte).  
* **Y-Achse:** Repr√§sentiert die Gr√∂√üe der √Ñnderung (*Delta*). Kleine Typos schweben oben, massive Text√§nderungen fallen nach unten.  
* **Modi:** Umschaltbar zwischen abstraktem "Daten-Tunnel" und "Globus-Ansicht" (Geografisches Mapping).

**Farb-Kodierung:**

* üîµ **Blau:** Bot-Aktivit√§t (Automatisierte Wartung)  
* üü° **Gelb/Orange:** Menschliche Erg√§nzung  
* üî¥ **Rot:** Menschliche L√∂schung (Vandalismus oder Bereinigung)

### **Auditive Parameter**

* **Frequenz:** Abgeleitet von der Titell√§nge des Artikels. L√§ngere Titel erzeugen tiefere, fundamentale Frequenzen.  
* **Klangfarbe (Timbre):** Unterscheidung zwischen Bot (*Digital/Square*) und Mensch (*Analog/Sawtooth*).  
* **R√§umlichkeit:** Stereo-Panning korrespondiert mit der visuellen Position auf dem Bildschirm.

### **Interaktivit√§t ("Mixing Desk")**

Der Nutzer kann die generative √Ñsthetik in Echtzeit beeinflussen:

1. **Balance:** Mischverh√§ltnis zwischen Bot- und Mensch-Edits.  
2. **Harmony:** Interpolation zwischen freier Atonalit√§t und quantisierter pentatonischer Skala.  
3. **Timbre:** Steuerung der Filter-Helligkeit und des visuellen "Glows".  
4. **Space:** Regelung des Hall-Anteils (*Reverb*) und der visuellen Partikel-Spuren.

## **Installation & Verwendung**

### **Variante A: Online Version (Empfohlen)**

Besuchen Sie einfach die Live-URL. Keine Installation notwendig.

[**https://maltemittrowann.com/wiki-sonic/**](https://maltemittrowann.com/wiki-sonic/)

*(Hinweis: Klicken Sie auf "Enter Experience", um den AudioContext zu starten)*

### **Variante B: Lokale Version (Python & SuperCollider)**

**Voraussetzungen:**

* Python 3.10 oder neuer  
* SuperCollider  
* Libraries: pip install requests python-osc pygame

**Schritt-f√ºr-Schritt Anleitung:**

1. **Audio-Engine starten:**  
   √ñffnen Sie Wikipedia-Synth.scd in SuperCollider. F√ºhren Sie den gesamten Code-Block aus (Strg+Enter), um den Server zu booten.  
2. **Visualisierung starten:**  
   python Wikipedia-Visualizer.py

   *(√ñffnet das Fenster und startet den OSC-Server f√ºr die Steuerung)*  
3. **Daten-Stream starten:**  
   python Wikipedia-Streaming.py

   *(Verbindet sich mit der Wikimedia API und sendet Daten)*

## **Lizenz & Credits**

**Autor:** Malte Mittrowann

**Kurs:** Generative Sound & Visual Art

**Repository:** [GitHub Link](https://github.com/MalteMittrowann/Generative_Sound-and-Visuals_from_Wikipedia-Streaming)

Dieses Projekt ist Open Source unter der **MIT Lizenz**.